

Plan: Sistema de colas DDD para descargas de música (MVP)
Implementación de arquitectura DDD completa para un sistema de descargas de música con cola FIFO, siguiendo el patrón demostrado en sample/. Sistema basado en yt-dlp con providers Bandcamp y YouTube Music, gestión de descargas (crear/consultar/actualizar/cancelar) y persistencia SQLite con cache decorator. Incluye tracking de archivos con rutas temporal y destino final, edición de metadata con validación, limpieza automática semanal de archivos huérfanos, cancelación de descargas activas, notificaciones en tiempo real via SSE con buffer circular en memoria para recuperación de eventos, throttling de eventos de progreso, rate limiting de enqueue (máx 10 pending), health check del worker, validación de URLs soportadas con normalización, logs estructurados con downloadId, prevención de duplicados por URL normalizada, timeout para descargas colgadas, verificación de espacio en disco con notificación, metadata nullable con edición posterior, y tracks como JSON completo.

Steps
Enriquecer capa de dominio — Añadir factory methods (fromYtDlpMetadata, fromDatabase, toJSON) a MediaItem y DownloadItem. En MediaItem permitir todos los campos nullable excepto id y provider, fromYtDlpMetadata tolera metadata incompleta asignando null. Extender DownloadItem con url: string, normalizedUrl: string, filePath: string | null, processId: number | null, startedAt: Date | null. Status: "pending" | "in_progress" | "completed" | "failed" | "cancelled". Añadir a DownloadRepository: findNextPending(), countByStatus(status), findByStatus(status, page, pageSize), updateProcessId(id, processId), findOldCompleted(days), findActiveByNormalizedUrl(normalizedUrl), findStalledInProgress(timeoutMinutes). Añadir a MediaRepository: updateMetadata(id, editableFields), findByProviderAndProviderId(provider, providerId).

Crear infraestructura de base de datos — Implementar src/lib/db/downloads/database.ts (singleton SQLite con WAL mode siguiendo database.ts) y queries.ts con schemas SQL: tabla media (id INTEGER PRIMARY KEY, title TEXT, artist TEXT, album TEXT, album_artist TEXT, year TEXT, cover_url TEXT, duration INTEGER, provider TEXT NOT NULL, provider_id TEXT, kind TEXT, tracks TEXT, created_at TEXT, updated_at TEXT), tabla downloads (id INTEGER PRIMARY KEY, url TEXT NOT NULL, normalized_url TEXT NOT NULL, media_id INTEGER FK, status TEXT NOT NULL, progress INTEGER DEFAULT 0, error_message TEXT, file_path TEXT, process_id INTEGER, created_at TEXT, started_at TEXT, finished_at TEXT). Índices: downloads.status, downloads.created_at, downloads.started_at, downloads.normalized_url, media.provider_id. UNIQUE constraint media(provider, provider_id). Index compuesto downloads(normalized_url, status), downloads(status, started_at).

Implementar repositorios SQLite — Crear src/core/infrastructure/downloads/SQLiteMediaRepository.ts y SQLiteDownloadRepository.ts siguiendo SQLiteBookmarksRepository. Implementar CRUD con manejo de nulls, findNextPending() con WHERE status='pending' ORDER BY created_at ASC LIMIT 1, countByStatus(status), findByStatus(status, page, pageSize) paginado, updateMetadata(id, editableFields) valida que editableFields no incluya provider/provider_id (throw error), solo actualiza title/artist/album/album_artist/year/cover_url/duration/tracks, actualiza updated_at, findByProviderAndProviderId(provider, providerId), findOldCompleted(days), updateProcessId(id, processId) actualiza process_id + started_at=datetime('now'), findActiveByNormalizedUrl(normalizedUrl) con WHERE normalized_url=? AND status IN ('pending','in_progress') LIMIT 1, findStalledInProgress(timeoutMinutes) con WHERE status='in_progress' AND started_at < datetime('now','-? minutes').

Implementar cache con decorator — Crear src/core/infrastructure/cache/CachedMediaRepository.ts y CachedDownloadRepository.ts siguiendo CachedBookmarksRepository. Usar withCache() de utils.ts. Cache keys: media:{id}, media:provider:{provider}:{providerId}, media:list:{page}:{perPage}, downloads:{id}, downloads:count:{status}, downloads:list:{page}:{perPage}:{status}, downloads:active-url:{normalizedUrl}. Invalidar en todas las operaciones de escritura. TTL: 5min media, 30s downloads.

Desarrollar servicios de aplicación — Extraer lógica de yt-dlp/index.ts a src/core/application/download/services/: UrlNormalizer (método normalize(url) que trim, lowercase protocol y domain, preserva path y query params, retorna string normalizada), PlatformDetector (regex bandcamp /bandcamp\.com\/(track|album)\//, ytmusic /music\.youtube\.com\/(watch|playlist)/, método validate(url) retorna {valid: boolean, provider: Provider | null}, throw error si no match), MetadataExtractor (spawn yt-dlp --skip-download --dump-json --flat-playlist, parsea JSON lines con try-catch por línea, mapea campos opcionales a null si faltan, retorna metadata con tracks array completo, logger warnings si incompleta), DownloadExecutor (spawn yt-dlp con configs bandcamp/ytmusic, parsea stderr con regex para progress, expone onProgress(callback), retorna {filePath: string, processId: number}, método cancel(processId) con process.kill(), logger context), StorageService (método checkAvailableSpace(path) usando Bun statfs, retorna bytes disponibles, método hasEnoughSpace(path, minGB) compara threshold). Env vars: DOWNLOAD_TEMP_DIR, DOWNLOAD_DEST_DIR, MIN_STORAGE_GB.

Implementar sistema de eventos SSE con buffer y throttling — Crear src/core/infrastructure/events/DownloadEventEmitter.ts extendiendo EventEmitter: buffer circular array de últimos N eventos con estructura {id: number, type: string, data: any, timestamp: number}, contador autoincremental nextId, Map progressThrottle: Map<downloadId, lastTimestamp>, método emitWithId(type, data) pushea evento a buffer (shift oldest si excede size) y emite con this.emit(type, eventData), método emitProgress(downloadId, progress) con throttling que verifica Map lastTimestamp skip si Date.now() - last < throttleMs actualiza Map si emite, método getEventsSince(lastId) retorna buffer.filter(e => e.id > lastId), método clearProgressThrottle(downloadId) limpia entry del Map. Tipos de eventos: download:enqueued, download:started, download:progress, download:completed, download:failed, download:cancelled, download:stalled, storage:low. Payload común: {downloadId, mediaId?, url, status, progress?, error?, filePath?, availableGB?}.

Crear use cases de operaciones — Implementar en src/core/application/download/use-cases/ inyectando repos, eventEmitter, logger, services: EnqueueDownload (normaliza URL con UrlNormalizer, valida con PlatformDetector throw 400 si invalid, verifica duplicados con findActiveByNormalizedUrl() throw 409 si existe, valida max pending con countByStatus('pending') throw 429 si >=10, crea Download con url + normalizedUrl + status='pending' + media_id=null, emite download:enqueued, spawn async background job: MetadataExtractor → si provider_id findByProviderAndProviderId() → crea Media si no existe con nulls permitidos → actualiza download.media_id, catch errors log warning sin fallar enqueue), ProcessDownload (obtiene Download, logger child context {downloadId}, verifica espacio hasEnoughSpace(TEMP_DIR, MIN_STORAGE_GB) si falla actualiza status='failed' + error='Insufficient storage' emite storage:low y download:failed throw 507, obtiene Media opcional, actualiza status='in_progress' + processId + started_at emite download:started, ejecuta DownloadExecutor con callback que actualiza progress en DB y llama eventEmitter.emitProgress() throttled, success actualiza status='completed' + file_path + finished_at emite download:completed, error actualiza status='failed' + error_message + finished_at emite download:failed), GetDownloadStatus, ListDownloads (page, perPage, status? filter), GetMediaDetails, UpdateMediaMetadata (valida que editableFields no incluya provider/provider_id throw 400, permite null en campos editables, llama updateMetadata()), MoveToDestination (Bun fs.rename de TEMP_DIR a DEST_DIR, actualiza file_path en DB). Patrón GetBookmarks.

Crear use cases de gestión — Implementar CancelDownload (verifica status='in_progress', llama DownloadExecutor.cancel(processId), actualiza status='cancelled' + error_message='Cancelled by user' + finished_at, llama eventEmitter.clearProgressThrottle(downloadId), emite download:cancelled), RetryDownload (verifica status='failed' o 'cancelled', resetea a pending con progress=0 error_message=null process_id=null started_at=null finished_at=null, emite download:enqueued), CleanupOrphanedFiles (ejecuta findOldCompleted(CLEANUP_RETENTION_DAYS), por cada download verifica existencia con Bun fs.exists, elimina archivos físicos en temp si status!='completed', elimina registros DB si archivo no existe, retorna {deletedFiles: number, deletedRecords: number, processedAt: timestamp}, logger con stats), MarkStalledDownloads (ejecuta findStalledInProgress(DOWNLOAD_TIMEOUT_MINUTES), por cada download actualiza status='failed' + error_message='Download timeout exceeded' + finished_at, limpia process_id, llama eventEmitter.clearProgressThrottle(downloadId), emite download:stalled, retorna {markedCount: number}).

Implementar worker FIFO con schedulers — Crear src/core/infrastructure/workers/DownloadWorker.ts: state object {running: boolean, currentDownloadId: number | null, lastProcessedAt: number | null, startedAt: number | null}, loop infinito mientras running=true con findNextPending() → actualiza state.currentDownloadId → crea logger child con context {downloadId} → await ProcessDownload.execute() → actualiza state.lastProcessedAt → limpia state.currentDownloadId, sin reintentos automáticos (failures quedan en status='failed'), sleep 2 segundos cuando no hay pending. Scheduler semanal cleanup: cleanupIntervalId = setInterval(() => CleanupOrphanedFiles.execute(), 7 * 24 * 60 * 60 * 1000). Scheduler cada 5min stalled: stalledIntervalId = setInterval(() => MarkStalledDownloads.execute(), 5 * 60 * 1000). Métodos: start() inicia loop y schedulers, stop() flag running=false + clearInterval ambos intervalIds, getStatus() retorna clone de state object, graceful shutdown con handlers process SIGTERM/SIGINT que llaman stop(). Logger pino lifecycle events (worker:started, worker:processing, worker:idle, worker:cleanup-scheduled, worker:stalled-check, worker:stopped). Iniciar worker en app.ts después de middleware antes de router.

Implementar handler SSE con recuperación — Crear handler en src/router/download/handlers.ts endpoint GET /downloads/events: extrae query param lastEventId?: string, parsea a number con parseInt, si existe y es número válido llama eventEmitter.getEventsSince(lastEventId) itera eventos perdidos del buffer escribiendo con stream.writeSSE({id: event.id.toString(), event: event.type, data: JSON.stringify(event.data)}), luego registra listeners para cada tipo de evento (download:enqueued, download:started, download:progress, download:completed, download:failed, download:cancelled, download:stalled, storage:low) que escriben nuevos eventos al stream con mismo formato, usa streamSSE helper de Hono, en stream.onAbort() hace removeListener para todos los tipos registrados limpieza de listeners. Browser maneja reconexión automática enviando Last-Event-ID header que handler recibe como query param.

Refactorizar capa API — Reestructurar router/download/ siguiendo router/api/bookmarks/: crear routes.ts con Hono OpenAPI + Zod schemas para validación: POST /downloads (body {url: string} con Zod URL validator, responses: 201 success con DTO, 400 invalid URL, 409 duplicate active, 429 max pending, 507 insufficient storage), GET /downloads/:id (param id number), GET /downloads (query: page number default 0, perPage number default 50, status enum optional), GET /downloads/events (query: lastEventId string optional, SSE stream response), GET /downloads/worker/status (retorna worker state JSON), PATCH /downloads/:id/cancel, POST /downloads/:id/retry, POST /downloads/:id/move (body {destinationPath?: string} Zod path validator), PATCH /media/:id (body con Zod schema para campos editables nullable), GET /media/:id, GET /media (query paginado). Crear handlers.ts con thin controllers que extraen params/body validados, llaman use cases correspondientes, manejan errores con try-catch retornando status codes apropiados, retornan DTOs via método toJSON() de entities. Handler worker status llama worker.getStatus(). Integrar routes en index.ts con composición.

Configurar inyección de dependencias — Crear src/core/config/downloads.ts siguiendo raindrop.ts: instanciar SQLiteMediaRepository, SQLiteDownloadRepository, wrap con CachedMediaRepository, CachedDownloadRepository pasando repos base como parámetro, instanciar DownloadEventEmitter singleton con buffer size y throttle interval de env vars, instanciar logger pino base, instanciar servicios con dependencias (UrlNormalizer, PlatformDetector, MetadataExtractor con logger, DownloadExecutor con logger, StorageService), construir todos los use cases inyectando dependencias necesarias (repos cached, eventEmitter, logger, storageService según necesite cada use case específico), instanciar DownloadWorker pasando use cases necesarios (ProcessDownload, CleanupOrphanedFiles, MarkStalledDownloads) y logger. Exportar: use cases configurados individuales, worker instance (expone método getStatus), eventEmitter instance para SSE handler. Cargar env vars con defaults: DOWNLOAD_TEMP_DIR, DOWNLOAD_DEST_DIR, DOWNLOAD_CACHE_TTL, CLEANUP_RETENTION_DAYS (default 7), MAX_PENDING_DOWNLOADS (default 10), EVENT_BUFFER_SIZE (default 100), PROGRESS_THROTTLE_MS (default 500), DOWNLOAD_TIMEOUT_MINUTES (default 60), MIN_STORAGE_GB (default 1).